\documentclass[14pt]{article}

\begin{document}
\title{Some Notes on Graph Mining}
\maketitle

\section{Into2GraphMining}
\begin{enumerate}
 \item A graph is said to be connected if there is path between every pair of vertices
 \item Two graphs $G_1(V_1,E_1)$ and $G_2(V_2,E_2)$ are said to be isomorphic if they are topologically identicle, which means a mapping from $V_1$ to $V_2$ exists so that each edge $E_1$ is mapped to a single edge in $E_2$ and vice-versa.
 \item Frequent subgraph mining (FSM)
  \begin{itemize}
   \item Given a set of undirected and labeled graphs ($D$) and a support threshold $\sigma$, find all connected and undirected graphs that are subgraphs in at least $\sigma \times D$ of input graphs.
  \end{itemize}
\end{enumerate}

\section{Complex networks tools for analyzing networks (R+igraph)}
\begin{enumerate}
 \item \texttt{igraph} can be used to handle undirected and directed graphs. It includes implementations for classic graph theory problems like minimum spanning trees and network flow and community structure search.
 \item Procefures for analyzing network
  \begin{itemize}
   \item Create a graph object
   \item Layout the network: use \texttt{igraph: tkplot}
   \item Ranking: use  \texttt{igraph: page.rank}
   \item Metrics
    \begin{itemize}
     \item \texttt{igraph: diameter(g)}
     \item \texttt{igraph: graph.density(g)}, i.e., $\frac{No.edges}{No.vertex \times (No.vertex-1)}$
     \item \texttt{igraph: average.path.length(g)}
     \item \texttt{igraph: transitivity(g)}
    \end{itemize}
   \item Community detection
   \item Export
  \end{itemize}
\end{enumerate}

\section{Practical statistical network analysis (with R and igraph)}
\begin{enumerate}
 \item \texttt{igraph} is for classic graph theory and network science. Its core functionality is implemented in C and has high level interfaces with $R$ and $Python$.
 \item Note that in the old version of \texttt{igraph}, vertices are always numbered from zero.
 \item Name vertices: \texttt{V(g)\$name}
 \item Graph representations
  \begin{itemize}
   \item Adjacency matrix
   \item Edge list
   \item Adjacency list
  \end{itemize}
 \item Some metrics
  \begin{itemize}
   \item degree
   \item closeness
   \item betweenness
   \item eigenvector centrality
   \item page rank
  \end{itemize}
\end{enumerate}

\section{Graph and web mining - motivation, applications and algorithms}
\begin{enumerate}
 \item The structure of the data is just as important as its content
 \item The discovered pattern can be used as compact representation of the information, find strongly connected groups and etc.
 \item Frequent patterns refer to a set of items, subsequences, and substructures that occur frequently in a data set. 
 \item Motivations for graph mining
  \begin{itemize}
   \item Most of existing DM algorithms are based on flat transaction representation, i.e., sets of items. 
   \item Data with structures, layers, hierarchy or geometry often do not fit well in this flat transaction setting.
  \end{itemize}
 \item Graph mining is essentially the problem of discovering repetitive subgraphs occuring in the input graphs.
 \item The main difference between association rules and graph patterns is that gaph patterns are topology-based, which means graph patterns have structure in addition to atomic values.
 \item Graph mining
  \begin{itemize}
   \item Frequent subgraph mining
    \begin{itemize}
     \item Apriori-based, e.g., AGM, FSG, PATH
     \item Pattern growth-based, e.g., gSpan, MoFa, GASTO, FFSM, SPIN
     \item Approximate methods, e.g., SUBDUE, GBI
    \end{itemize}
   \item Variant subgraph pattern mining
    \begin{itemize}
     \item Closed subgraph mining, e.g., CloseGraph
     \item Coherent subgraph mining, e.g., CSA, CLAN
     \item Dense subgraph mining, e.g., CloseCut, Splat, CODENS
    \end{itemize}
   \item Applications of FSM
    \begin{itemize}
     \item Clustering
     \item Classification, e.g., kernel methods (graph kernels)
     \item Indexing and search, e.g., gIndex
    \end{itemize}
  \end{itemize}
\end{enumerate}

\section{Introduction to igraph}
\begin{enumerate}
 \item Creating a graph
  \begin{itemize}
   \item Attributes include color and weight
   \item \texttt{plot(g, edge.width=2+3*E(g)\$weight, vertex.label=NA, vertex.size=2)}
  \end{itemize}
 \item Measuring graphs
  \begin{itemize}
   \item \texttt{diameter}
   \item \texttt{transitivity}: cluster coefficient or transitivity
   \item \texttt{average.path.length}
   \item \texttt{degree}
   \item \texttt{degree.distribution}
  \end{itemize}
\end{enumerate}

\section{Community detection algorithms in igraph}
\begin{enumerate}
 \item Algorithms 
 \begin{itemize}
  \item \texttt{edge.between.community}, 2004
  \item \texttt{fashgreedy.community}, 2004, i.e., modularity optimization method
  \item \texttt{label.propagation.community}, 2007
  \item \texttt{leading.eigenvector.community}, 2006
  \item \texttt{multilevel.community}, 2008, i.e., the Louvain method
  \item \texttt{optimal.community}, 2008
  \item \texttt{singlass.community}, 2006
  \item \texttt{walkstrap.community}, 2005
  \item \texttt{infomap.community}, 2008
 \end{itemize}
 
 \item Evaluation criteria
  \begin{itemize}
   \item \texttt{modularity}
   \item \texttt{conductance}
   \item \texttt{cut ratio}
   \item \texttt{expansion}
  \end{itemize}
\end{enumerate}

\section{Graph mining and graph kernels}
\begin{enumerate}
 \item FSM algorithms
  \begin{itemize}
   \item Apriori-based approaches, e.g., AGM/AcGM, FSG, PATH, FFSM, FTOSM
   \item Pattern growth approaches, e.g., SUBDUE, gSpan, MoFa, Gaston, CMTreeMiner, LEAP
  \end{itemize}
 
 \item For Apriori-based approaches, the logic behind is that if a graph is frequent, all of its subgraphes are frequent.
 
 \item Properties of graph mining algorithms
  \begin{itemize}
   \item Search order: breadth or depth, complete or incomplete
   \item Candidate generation mechanism: apriori or pattern growth
   \item Discovery order of patterns: DFS oder, or $path \rightarrow tree \rightarrow graph$
   \item Elimination of duplicate subgraphs: passive or active
   \item Support calculation: embedding store or not
  \end{itemize}
 
 \item Pattern summarization aims to use a small set of representative patterns which preserve most of the information to represent the original data
 
 \item A frequent graph $G$ is closed if there exists no supergraph of $G$ that carries the same support of $G$.
 
 \item A frequent graph $G$ is maximal if there exists no supergraph of $G$ that is frequent.
 
 \item Graph kernels aim to compute similarity scores between graphs
 
 \item Two graphs $G_1$ and $G_2$ are said to be isomorphic if there is a mapping function $f$, such that for each edge $(x,y)$ in $G_1$, there is a corresponding edge in $G_2$ and it is $(f(x), f(y))$. $f$ is said to be the isomorphism. Note that there is no polynomial-time algorithm in solving graph isomorphism. It is known to be NP-complete.
 
 \item Subgraph isomorphism asks if there is a subset of edges and vertices of $G_1$ that is isomorphic to a smaller graph $G_2$. Subgraph isomorphism is also NP-complete.
 
 \item Graph edit distances
  \begin{itemize}
   \item The principle is to count the operations to transform $G_1$ to $G_2$. Assign costs to different types of operations, including edge/node insertion or deletion, modification of labels. 
   \item It can partially capture the similarities between graphs. It allos for noise in the nodes, edges and their labels. 
   \item One disadvantage is that it has to contain a subgraph isomorphism chec step as one intermediate step. In addition, choosing cost function for different operations can be difficult.
  \end{itemize}
  
 \item Topological descriptors
  \begin{itemize}
   \item The principle is to map each graph to a feature vector and use distances and metrics on vector for learning in graphs.
   \item The advantage is that it can utilize the tools for feature vectors
   \item The disadvantage is that the feature vector transformation leads to information loss
  \end{itemize}
 
 \item Polynomial alternatives
  \begin{itemize}
   \item Graph kernels compare the substructures in polynomial time
   \item A good graph kernel should be expressive, efficient to compute, positive definite, and applicable to wide range of graphs 
  \end{itemize}
 
\end{enumerate}





\end{document}